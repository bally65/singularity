{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Singularity V3 - AI Model Training\n",
    "\n",
    "Developed by Molty for Bally. This notebook implements the **V3 Architecture**: \n",
    "- **Temporal CNN** for local feature extraction\n",
    "- **Bi-LSTM** for sequence dependency\n",
    "- **Multi-Head Attention** for global context\n",
    "- **Huber Loss** for robust regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Environment\n",
    "!pip install torch pandas numpy scikit-learn matplotlib\n",
    "\n",
    "# --- NEW: Merge Data Chunks from GitHub ---\n",
    "!cat dataset.csv.part* > dataset.csv\n",
    "print(\"âœ… Dataset merged from chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "SEQ_LENGTH = 60\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4\n",
    "FEATURE_COLS = ['velocity', 'accel', 'entropy', 'mass', 'imbalance', 'liq_force']\n",
    "TARGET_COL = 'label_return_60s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Data\n",
    "Please upload your `dataset.csv` using the folder icon on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. æ•¸æ“šæŠ“å–èˆ‡åˆä½µ ---\n",
    "if not os.path.exists('dataset.csv'):\n",
    "    print(\"ğŸš€ æ­£åœ¨å¾ GitHub æŠ“å–æ•¸æ“šå¡Š...\")\n",
    "    !wget -q https://raw.githubusercontent.com/bally65/singularity/master/dataset.csv.partaa\n",
    "    !wget -q https://raw.githubusercontent.com/bally65/singularity/master/dataset.csv.partab\n",
    "    !wget -q https://raw.githubusercontent.com/bally65/singularity/master/dataset.csv.partac\n",
    "    !wget -q https://raw.githubusercontent.com/bally65/singularity/master/dataset.csv.partad\n",
    "    print(\"ğŸ“‚ æ­£åœ¨åˆä½µæ•¸æ“šå¡Š...\")\n",
    "    !cat dataset.csv.part* > dataset.csv\n",
    "else:\n",
    "    print(\"ğŸ“¦ æ•¸æ“šæª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³éæŠ“å–ã€‚\")\n",
    "\n",
    "# --- 2. æ•¸æ“šè®€å–èˆ‡æ¸…ç† ---\n",
    "print(\"ğŸ“Š æ­£åœ¨è®€å–æ•¸æ“š (è‡ªå‹•ä¿®å¾©æ¥ç¸«éŒ¯èª¤)...\")\n",
    "try:\n",
    "    # ä½¿ç”¨ on_bad_lines='skip' è™•ç†åˆ†å‰²ç”¢ç”Ÿçš„æ®˜ç¼ºè¡Œ\n",
    "    df = pd.read_csv('dataset.csv', on_bad_lines='skip', low_memory=False).dropna()\n",
    "    print(f\"âœ… æˆåŠŸè®€å– {len(df)} ç­†æœ‰æ•ˆæ•¸æ“šï¼\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ è®€å–å¤±æ•—: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Model V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.features)\n",
    "    def __getitem__(self, idx): return self.features[idx], self.labels[idx]\n",
    "\n",
    "class SingularityV3Model(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=128, nhead=8):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(input_dim, d_model, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(d_model, d_model, num_layers=2, batch_first=True, dropout=0.1)\n",
    "        self.attn = nn.MultiheadAttention(d_model, nhead, dropout=0.1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3) # [Q10, Q50, Q90]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        attn_in = lstm_out.transpose(0, 1)\n",
    "        attn_out, _ = self.attn(attn_in, attn_in, attn_in)\n",
    "        last_state = attn_out[-1]\n",
    "        return self.head(last_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "train_loader = DataLoader(FinancialDataset(X_train, Y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(FinancialDataset(X_val, Y_val), batch_size=BATCH_SIZE)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SingularityV3Model(len(FEATURE_COLS)).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.HuberLoss()\n",
    "\n",
    "train_losses = []\n",
    "print(f\"ğŸš€ Training V3 on {device}...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)[:, 1] # Target median\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss/len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {avg_loss:.6f}\")\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.title(\"V3 Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export to ONNX\n",
    "This will create `singularity_v3.onnx` for the Go Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "dummy = torch.randn(1, SEQ_LENGTH, len(FEATURE_COLS)).to(device)\n",
    "torch.onnx.export(model, dummy, \"singularity_v3.onnx\", input_names=['input'], output_names=['output'])\n",
    "print(\"âœ… Done! Download singularity_v3.onnx and put it in your Go project root.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
